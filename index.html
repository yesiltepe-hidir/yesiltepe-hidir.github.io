<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://www.w3counter.com/tracker.js?id=154788"></script>
    <title>Hidir Yesiltepe - AI Researcher</title>
    <link rel="stylesheet" href="static/style.css">
    </head>
<body>
    <div class="social-bar">
        <div class="container">
            <div class="social-icons">
                <a href="https://scholar.google.com/citations?hl=en&user=9RxXfaUAAAAJ" target="_blank" title="Google Scholar">
                    <i class="ai ai-google-scholar"></i>
                </a>
                <a href="https://www.linkedin.com/in/hidiryesiltepe/" target="_blank" title="LinkedIn">
                    <i class="fab fa-linkedin-in"></i>
                </a>
                <a href="https://github.com/yesiltepe-hidir" target="_blank" title="GitHub">
                    <i class="fab fa-github"></i>
                </a>
                <a href="static/Yesiltepe_Hidir_Website_Resume.pdf" class="cv-link" target="_blank" title="Download CV">
                    <i class="fas fa-file-alt"></i>
                    <span>CV</span>
                </a>
            </div>
        </div>
    </div>

    <header>
        <div class="container header-content">
            <div class="profile-info">
                <h1>Hidir Yesiltepe</h1>
                <div class="subtitle" style="font-family: 'JetBrains Mono', monospace;">Ph.D. Student in Computer Science at Virginia Tech</div>
                <div class="subtitle" style="font-family: 'JetBrains Mono', monospace;">Generative AI Researcher</div>
                <div class="subtitle" style="font-family: 'JetBrains Mono', monospace;">> hidir[at]vt[dot]edu</div>
            </div>
            <div class="profile-image">
                <img src="static/profile_picture.jpeg" alt="Hidir Yesiltepe">
            </div>
        </div>
    </header>

    <nav>
        <div class="container">
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#research">Research</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <section id="about">
        <div class="container">
            <h2>About</h2>
            <p>I am a Ph.D. student in the Department of Computer Science at Virginia Tech, focusing on generative AI. My research interests include text-to-image generation, video editing, and motion transfer. Previously, I interned as an Applied Scientist at Amazon.</p>
        </div>
    </section>

    <section id="research">
        <div class="container">
            <h2>Research Philosophy</h2>
            <p>I believe that transformative research often emerges from working within constraints. In academia, where we face computational limitations compared to large tech companies, I've turned this challenge into an opportunity for innovation. My work is characterized by training-free approaches that emphasize creativity over computational power. My aim is developing a signature style of research that focuses on creating impactful solutions that are both elegant and accessible.</p>
        </div>
    </section>

    <section id="publications">
        <div class="container">
            <h2>Selected Publications</h2>
            <div class="publications">
                <a href="https://motionshop-diffusion.github.io/" style="text-decoration: none;" target=â€_blankâ€>
                <div class="publication">
                    <div class="publication-gif">
                        <img src="static/MotionShop_Teaser.gif" alt="MotionShop Demo">
                    </div>
                    <div class="publication-content">
                        <h3>MotionShop: Zero-Shot Motion Transfer in Video Diffusion Models with Mixture of Score Guidance</h3>
                        <div class="publication-authors">
                            <span class="author-highlight">Hidir Yesiltepe</span>, Tuna Han Salih Meral, Conor Dunlop, Pinar Yanardag
                        </div>
                        <div class="publication-meta">Preprint, 2024</div>
                        <div class="tags">
                            <span class="tag">Video Editing</span>
                            <span class="tag">Motion Transfer</span>
                            <span class="tag">Flow Matching</span>
                        </div>
                    </div>
                </div>
            </a>

            <a href="https://motionflow-diffusion.github.io/" style="text-decoration: none;" target=â€_blankâ€>
                <div class="publication">
                    <div class="publication-gif">
                        <img src="static/MotionFlow_Teaser.gif" alt="MotionFlow Demo">
                    </div>
                    <div class="publication-content">
                        <h3>MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models</h3>
                        <div class="publication-authors">
                            Tuna Han Salih Meral, <span class="author-highlight">Hidir Yesiltepe</span>, Conor Dunlop, Pinar Yanardag
                        </div>
                        <div class="publication-meta">Preprint, 2024</div>
                        <div class="tags">
                            <span class="tag">Video Editing</span>
                            <span class="tag">Motion Transfer</span>
                            <span class="tag">Flow Matching</span>
                        </div>
                    </div>
                </div>
            </a>

            <a href="https://rave-video.github.io/" style="text-decoration: none;" target=â€_blankâ€>
                <div class="publication">
                    <div class="publication-gif">
                        <img src="static/RAVE_Teaser.gif" alt="MotionFlow Demo">
                    </div>
                    <div class="publication-content">
                        <h3>RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models</h3>
                        <div class="publication-authors">
                            Ozgur Kara, Bariscan Kurtkaya, <span class="author-highlight">Hidir Yesiltepe</span>, James M. Rehg, Pinar Yanardag
                        </div>
                        <div class="publication-meta">CVPR 2024 (Highlight)</div>
                        <div class="tags">
                            <span class="tag">Video Editing</span>
                            <span class="tag">Diffusion Models</span>
                        </div>
                    </div>
                </div>
            </a>

            <a href="https://arxiv.org/abs/2406.00457" style="text-decoration: none;" target=â€_blankâ€>
                <div class="publication">
                    <div class="publication-gif">
                        <img src="static/EOS_Teaser.png" alt="EOS Demo">
                    </div>
                    <div class="publication-content">
                        <h3>The Curious Case of End Token: A Zero-Shot Disentangled Image Editing using CLIP</h3>
                        <div class="publication-authors">
                            <span class="author-highlight">Hidir Yesiltepe</span>, Yusuf Dalva, Pinar Yanardag
                        </div>
                        <div class="publication-meta">CVPR 2024 - AI4CC Workshop</div>
                        <div class="tags">
                            <span class="tag">Image Editing</span>
                            <span class="tag">Diffusion Models</span>
                        </div>
                    </div>
                </div>
            </a>

            <a href="https://stylebreeder.github.io/" style="text-decoration: none;" target=â€_blankâ€>
                <div class="publication">
                    <div class="publication-gif">
                        <img src="static/Stylebreeder_Teaser.png" alt="Stylebreeder Demo">
                    </div>
                    <div class="publication-content">
                        <h3>Stylebreeder ðŸŽ¨: Exploring and Democratizing Artistic Styles through Text-to-Image Models</h3>
                        <div class="publication-authors">
                            Matthew Zheng, Enis Simsar, <span class="author-highlight">Hidir Yesiltepe</span>, Federico Tombari, Joel Simon, Pinar Yanardag
                        </div>
                        <div class="publication-meta">NeurIPS 2024</div>
                        <div class="tags">
                            <span class="tag">Image Stylization</span>
                            <span class="tag">Diffusion Models</span>
                        </div>
                    </div>
                </div>
            </a>

                
    </section>

    <section id="contact">
        <div class="container">
            <h2>Contact</h2>
            <p>Feel free to reach out for research collaborations or inquiries.</p>
            <div class="social-links">
                <a href="https://scholar.google.com/citations?hl=en&user=9RxXfaUAAAAJ">Google Scholar</a>
                <a href="https://github.com/yesiltepe-hidir">GitHub</a>
                <a href="https://www.linkedin.com/in/hidiryesiltepe/">LinkedIn</a>
                <a href="hidir@vt.edu">Email</a>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>Â© 2024 Hidir Yesiltepe. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>